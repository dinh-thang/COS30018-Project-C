{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0e352b7224f8478fabf5d579315f747b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_25ce885b17ae4b8cbd99d6b7fa20f3be",
              "IPY_MODEL_0a35638e69b641de9b377c38048f61e8",
              "IPY_MODEL_9c26f0ef6f8a40cb8a34ab0ce44c833f"
            ],
            "layout": "IPY_MODEL_6b967769e0444824b3ae20b48f4d7d77"
          }
        },
        "25ce885b17ae4b8cbd99d6b7fa20f3be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bbf1662d33c4066b8cac590066da789",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_93cbc12e4d1d495faadca665ddb562d3",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "0a35638e69b641de9b377c38048f61e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb8a6bc915d04b9b9fc6e90a31c85f50",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_66c526a565a74c3fa99a0213adb37a33",
            "value": 8
          }
        },
        "9c26f0ef6f8a40cb8a34ab0ce44c833f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3abba6222c9428f8d382c213d58f860",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_90ee6134ae784ae693471cf50ff21849",
            "value": " 8/8 [01:48&lt;00:00, 11.73s/it]"
          }
        },
        "6b967769e0444824b3ae20b48f4d7d77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bbf1662d33c4066b8cac590066da789": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93cbc12e4d1d495faadca665ddb562d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb8a6bc915d04b9b9fc6e90a31c85f50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66c526a565a74c3fa99a0213adb37a33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d3abba6222c9428f8d382c213d58f860": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90ee6134ae784ae693471cf50ff21849": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGuVf-GuGlJU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finetune Falcon-7b (sharded version) on a Google colab notebook\n",
        "\n",
        "Project C - Team 4"
      ],
      "metadata": {
        "id": "C2EgqEPDQ8v6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "The used libraries are `accelerate`, `peft`, `transformers`, `datasets` and TRL to leverage the recent `SFTTrainer`. We will use `bitsandbytes` to quantize the base model into 4bit (QLoRA approach). We will also install `einops` as it is a requirement to load Falcon models."
      ],
      "metadata": {
        "id": "i-tTvEF1RT3y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNnkgBq7Q3EU",
        "outputId": "3ab2cb85-7f38-4f8f-f9f8-2d82dc796fa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q -U trl transformers accelerate git+https://github.com/huggingface/peft.git\n",
        "!pip install -q datasets bitsandbytes einops wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset load\n",
        "\n",
        "We make use of PubMedQA, which has more than 200000 instances (Artificially created)\n",
        "\n",
        "The dataset can be found [here](https://huggingface.co/datasets/pubmed_qa)"
      ],
      "metadata": {
        "id": "Rnqmq7amRrU8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset_name = \"minh21/cpgQA-v1.0-unique-context-test-10-percent-validation-10-percent\"\n",
        "dataset = load_dataset(dataset_name, split=\"train\")"
      ],
      "metadata": {
        "id": "0X3kHnskSWU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the model"
      ],
      "metadata": {
        "id": "rjOMoSbGSxx9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section we will load the [Falcon 7B model](https://huggingface.co/tiiuae/falcon-7b), quantize it in 4bit and attach LoRA adapters on it. Let's get started!"
      ],
      "metadata": {
        "id": "AjB0WAqFSzlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, AutoTokenizer\n",
        "\n",
        "model_name = \"ybelkada/falcon-7b-sharded-bf16\"\n",
        "\n",
        "#Quantizer initialize\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        ")\n",
        "\n",
        "#Get model from HuggingFace's transformers library\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=bnb_config,\n",
        "    trust_remote_code=True\n",
        ")\n",
        "model.config.use_cache = False"
      ],
      "metadata": {
        "id": "ZwXZbQ2dSwzI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "0e352b7224f8478fabf5d579315f747b",
            "25ce885b17ae4b8cbd99d6b7fa20f3be",
            "0a35638e69b641de9b377c38048f61e8",
            "9c26f0ef6f8a40cb8a34ab0ce44c833f",
            "6b967769e0444824b3ae20b48f4d7d77",
            "6bbf1662d33c4066b8cac590066da789",
            "93cbc12e4d1d495faadca665ddb562d3",
            "fb8a6bc915d04b9b9fc6e90a31c85f50",
            "66c526a565a74c3fa99a0213adb37a33",
            "d3abba6222c9428f8d382c213d58f860",
            "90ee6134ae784ae693471cf50ff21849"
          ]
        },
        "outputId": "9d6599f1-ca2b-4f23-d817-5ef1f0cfeb55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e352b7224f8478fabf5d579315f747b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "id": "XDS2yYmlUAD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below we will load the configuration file in order to create the LoRA model. According to QLoRA paper, it is important to consider all linear layers in the transformer block for maximum performance. Therefore we will add `dense`, `dense_h_to_4_h` and `dense_4h_to_h` layers in the target modules in addition to the mixed query key value layer."
      ],
      "metadata": {
        "id": "NuAx3zBeUL1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3xKJ4Etjrfk",
        "outputId": "b5b1e86e-2ca5-42ea-fc71-56eea3406af8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T5ForConditionalGeneration(\n",
            "  (shared): Embedding(32128, 512)\n",
            "  (encoder): T5Stack(\n",
            "    (embed_tokens): Embedding(32128, 512)\n",
            "    (block): ModuleList(\n",
            "      (0): T5Block(\n",
            "        (layer): ModuleList(\n",
            "          (0): T5LayerSelfAttention(\n",
            "            (SelfAttention): T5Attention(\n",
            "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
            "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
            "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
            "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
            "              (relative_attention_bias): Embedding(32, 8)\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (1): T5LayerFF(\n",
            "            (DenseReluDense): T5DenseActDense(\n",
            "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
            "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "              (act): ReLU()\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (1-5): 5 x T5Block(\n",
            "        (layer): ModuleList(\n",
            "          (0): T5LayerSelfAttention(\n",
            "            (SelfAttention): T5Attention(\n",
            "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
            "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
            "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
            "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (1): T5LayerFF(\n",
            "            (DenseReluDense): T5DenseActDense(\n",
            "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
            "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "              (act): ReLU()\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (final_layer_norm): T5LayerNorm()\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (decoder): T5Stack(\n",
            "    (embed_tokens): Embedding(32128, 512)\n",
            "    (block): ModuleList(\n",
            "      (0): T5Block(\n",
            "        (layer): ModuleList(\n",
            "          (0): T5LayerSelfAttention(\n",
            "            (SelfAttention): T5Attention(\n",
            "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
            "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
            "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
            "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
            "              (relative_attention_bias): Embedding(32, 8)\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (1): T5LayerCrossAttention(\n",
            "            (EncDecAttention): T5Attention(\n",
            "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
            "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
            "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
            "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (2): T5LayerFF(\n",
            "            (DenseReluDense): T5DenseActDense(\n",
            "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
            "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "              (act): ReLU()\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (1-5): 5 x T5Block(\n",
            "        (layer): ModuleList(\n",
            "          (0): T5LayerSelfAttention(\n",
            "            (SelfAttention): T5Attention(\n",
            "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
            "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
            "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
            "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (1): T5LayerCrossAttention(\n",
            "            (EncDecAttention): T5Attention(\n",
            "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
            "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
            "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
            "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (2): T5LayerFF(\n",
            "            (DenseReluDense): T5DenseActDense(\n",
            "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
            "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "              (act): ReLU()\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (final_layer_norm): T5LayerNorm()\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig\n",
        "\n",
        "#Setup numerical value for LoRA\n",
        "lora_alpha = 16\n",
        "lora_dropout = 0.1\n",
        "lora_r = 64\n",
        "\n",
        "#Use LoRA config for fine-tuning this model\n",
        "peft_config = LoraConfig(\n",
        "    lora_alpha=lora_alpha,\n",
        "    lora_dropout=lora_dropout,\n",
        "    r=lora_r,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "        target_modules=[\n",
        "    \"q\",\n",
        "    \"o\",\n",
        "    \"k\",\n",
        "    \"v\"]\n",
        ")"
      ],
      "metadata": {
        "id": "dQdvjTYTT1vQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the trainer"
      ],
      "metadata": {
        "id": "dzsYHLwIZoLm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we will use the [`SFTTrainer` from TRL library](https://huggingface.co/docs/trl/main/en/sft_trainer) that gives a wrapper around transformers `Trainer` to easily fine-tune models on instruction based datasets using PEFT adapters. Let's first load the training arguments below."
      ],
      "metadata": {
        "id": "aTBJVE4PaJwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "#Arguments needed for training process\n",
        "output_dir = \"falcon-7b-sharded\"\n",
        "per_device_train_batch_size = 4\n",
        "gradient_accumulation_steps = 4\n",
        "#Paged adamw 32 bits optimization algorithm is used in QLoRA\n",
        "optim = \"paged_adamw_32bit\"\n",
        "save_steps = 10\n",
        "logging_steps = 10\n",
        "learning_rate = 2e-4\n",
        "max_grad_norm = 0.3\n",
        "max_steps = 200\n",
        "warmup_ratio = 0.03\n",
        "lr_scheduler_type = \"constant\"\n",
        "\n",
        "training_arguments = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    per_device_train_batch_size=per_device_train_batch_size,\n",
        "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "    optim=optim,\n",
        "    save_steps=save_steps,\n",
        "    logging_steps=logging_steps,\n",
        "    learning_rate=learning_rate,\n",
        "    fp16=True,\n",
        "    max_grad_norm=max_grad_norm,\n",
        "    max_steps=max_steps,\n",
        "    warmup_ratio=warmup_ratio,\n",
        "    group_by_length=True,\n",
        "    lr_scheduler_type=lr_scheduler_type,\n",
        "    report_to=None\n",
        ")"
      ],
      "metadata": {
        "id": "OCFTvGW6aspE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Use 30000 random data from dataset, 30% for test, 70% for training\n",
        "print(dataset)"
      ],
      "metadata": {
        "id": "2EWkO9U2fNaV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57c90493-1575-4002-8258-d1da0c7c0a14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['title', 'id', 'question', 'answer_text', 'answer_start', 'context'],\n",
            "    num_rows: 884\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
        "\n",
        "#Format the input\n",
        "tokenizer=AutoTokenizer.from_pretrained('T5-small')\n",
        "model=AutoModelWithLMHead.from_pretrained('T5-small', return_dict=True)\n",
        "\n",
        "def summarize(row):\n",
        "    words = torch.split(row['context'], \" \")\n",
        "    word_count = len(words)\n",
        "    if word_count > 512:\n",
        "      inputs=tokenizer.encode(\"sumarize: \" +row['context'],return_tensors='pt', max_length=512, truncation=True)\n",
        "      output = model.generate(inputs, min_length=80, max_length=512)\n",
        "      summary=tokenizer.decode(output[0])\n",
        "      row['context'] = summary\n",
        "    return row\n",
        "\n",
        "def get_text(row):\n",
        "  row['text'] = \"### Context: \" + row['context'] +  \"### Question: \" + row['question'] + \"### Answer: \" + row['answer_text']\n",
        "  return row\n",
        "\n",
        "dataset_train = dataset\n",
        "dataset_train.add_column(name=\"text\", column=dataset_train['answer_text'])\n",
        "dataset_train = dataset_train.map(summarize)\n",
        "for i in range(10):\n",
        "  print(dataset_train['context'][i])\n",
        "dataset_train = dataset_train.map(get_text,  remove_columns=dataset.column_names)"
      ],
      "metadata": {
        "id": "4EoeY7k_zOS5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6951d75-3e7e-463d-85da-20aae8a34db3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/modeling_auto.py:1479: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Opioid Taper Decision Tool is designed to assist Primary Care providers in determining if an opioid taper is necessary for a specific patient, in performing the taper, and in providing follow-up and support during the taper.\n",
            "Opioids are not first-line or routine therapy for chronic pain. Establish treatment goals before starting opioid therapy and a plan if therapy is discontinued. Only continue opioid if there is clinically meaningful improvement in pain and function. Discuss risks, benefits and responsibilities for managing therapy before starting and during treatment.\n",
            "Opioids are not first-line or routine therapy for chronic pain. Establish treatment goals before starting opioid therapy and a plan if therapy is discontinued. Only continue opioid if there is clinically meaningful improvement in pain and function. Discuss risks, benefits and responsibilities for managing therapy before starting and during treatment.\n",
            "Opioids are not first-line or routine therapy for chronic pain. Establish treatment goals before starting opioid therapy and a plan if therapy is discontinued. Only continue opioid if there is clinically meaningful improvement in pain and function. Discuss risks, benefits and responsibilities for managing therapy before starting and during treatment.\n",
            "Opioids are not first-line or routine therapy for chronic pain. Establish treatment goals before starting opioid therapy and a plan if therapy is discontinued. Only continue opioid if there is clinically meaningful improvement in pain and function. Discuss risks, benefits and responsibilities for managing therapy before starting and during treatment.\n",
            "Opioids are not first-line or routine therapy for chronic pain. Establish treatment goals before starting opioid therapy and a plan if therapy is discontinued. Only continue opioid if there is clinically meaningful improvement in pain and function. Discuss risks, benefits and responsibilities for managing therapy before starting and during treatment.\n",
            "Opioids are not first-line or routine therapy for chronic pain. Establish treatment goals before starting opioid therapy and a plan if therapy is discontinued. Only continue opioid if there is clinically meaningful improvement in pain and function. Discuss risks, benefits and responsibilities for managing therapy before starting and during treatment.\n",
            "Use immediate-release (IR) opioids when starting therapy. Prescribe the lowest effective dose. When using opioids for acute pain, provide no more than needed for the condition. Follow up and review benefits and risks before starting and during therapy. If benefits do not outweigh harms, consider tapering opioids to lower doses or taper and discontinue.\n",
            "Use immediate-release (IR) opioids when starting therapy. Prescribe the lowest effective dose. When using opioids for acute pain, provide no more than needed for the condition. Follow up and review benefits and risks before starting and during therapy. If benefits do not outweigh harms, consider tapering opioids to lower doses or taper and discontinue.\n",
            "Use immediate-release (IR) opioids when starting therapy. Prescribe the lowest effective dose. When using opioids for acute pain, provide no more than needed for the condition. Follow up and review benefits and risks before starting and during therapy. If benefits do not outweigh harms, consider tapering opioids to lower doses or taper and discontinue.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get text example\n",
        "#print(dataset_train['text'][0])\n",
        "tokens = tokenizer.tokenize(\"### Human: Can you write a short introduction about the relevance of the term \\\"monopsony\\\" in economics? Please use examples related to potential monopsonies in the labour market and cite relevant research.### Assistant: \\\"Monopsony\\\" refers to a market structure where there is only one buyer for a particular good or service. In economics, this term is particularly relevant in the labor market, where a monopsony employer has significant power over the wages and working conditions of their employees. The presence of a monopsony can result in lower wages and reduced employment opportunities for workers, as the employer has little incentive to increase wages or provide better working conditions.\\n\\nRecent research has identified potential monopsonies in industries such as retail and fast food, where a few large companies control a significant portion of the market (Bivens & Mishel, 2013). In these industries, workers often face low wages, limited benefits, and reduced bargaining power, leading to a situation where they are dependent on the employer for their livelihood. This dependence can result in further suppression of wages and a decline in working conditions.\\n\\nOverall, the concept of monopsony is essential to understanding the dynamics of labor markets and the impact of market power on workers. Further research is needed to understand the extent and impact of monopsonies on the economy and to develop policies to address this issue.\\n\\nReferences:\\nBivens, J., & Mishel, L. (2013). The Pay of Corporate Executives and Financial Professionals as Evidence of Rents in Top 1 Percent Incomes. Journal of Economic Perspectives, 27(3), 57-78.### Human: Now explain it to a dog\")\n",
        "print(tokenizer.convert_tokens_to_ids(tokens))"
      ],
      "metadata": {
        "id": "DNS-eonR2cNw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc1c3225-e246-4d6c-8508-337d8457b8ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1713, 30345, 3892, 10, 1072, 25, 1431, 3, 9, 710, 5302, 81, 8, 20208, 13, 8, 1657, 96, 2157, 9280, 106, 63, 121, 16, 1456, 7, 58, 863, 169, 4062, 1341, 12, 1055, 7414, 102, 739, 725, 16, 8, 12568, 512, 11, 3, 8464, 2193, 585, 5, 4663, 30345, 9255, 10, 96, 9168, 9280, 106, 63, 121, 2401, 7, 12, 3, 9, 512, 1809, 213, 132, 19, 163, 80, 8001, 21, 3, 9, 1090, 207, 42, 313, 5, 86, 1456, 7, 6, 48, 1657, 19, 1989, 2193, 16, 8, 5347, 512, 6, 213, 3, 9, 7414, 102, 739, 63, 6152, 65, 1516, 579, 147, 8, 15488, 11, 464, 1124, 13, 70, 1652, 5, 37, 3053, 13, 3, 9, 7414, 102, 739, 63, 54, 741, 16, 1364, 15488, 11, 3915, 4311, 1645, 21, 2765, 6, 38, 8, 6152, 65, 385, 17821, 12, 993, 15488, 42, 370, 394, 464, 1124, 5, 17716, 585, 65, 4313, 1055, 7414, 102, 739, 725, 16, 5238, 224, 38, 3549, 11, 1006, 542, 6, 213, 3, 9, 360, 508, 688, 610, 3, 9, 1516, 4149, 13, 8, 512, 41, 279, 757, 29, 7, 3, 184, 8306, 88, 40, 6, 2038, 137, 86, 175, 5238, 6, 2765, 557, 522, 731, 15488, 6, 1643, 1393, 6, 11, 3915, 13435, 53, 579, 6, 1374, 12, 3, 9, 1419, 213, 79, 33, 8976, 30, 8, 6152, 21, 70, 27656, 5, 100, 24264, 54, 741, 16, 856, 23059, 13, 15488, 11, 3, 9, 7198, 16, 464, 1124, 5, 9126, 6, 8, 2077, 13, 7414, 102, 739, 63, 19, 1832, 12, 1705, 8, 14966, 13, 5347, 3212, 11, 8, 1113, 13, 512, 579, 30, 2765, 5, 9006, 585, 19, 906, 12, 734, 8, 5996, 11, 1113, 13, 7414, 102, 739, 725, 30, 8, 2717, 11, 12, 1344, 3101, 12, 1115, 48, 962, 5, 17881, 7, 10, 2106, 1926, 7, 6, 446, 5, 6, 3, 184, 8306, 88, 40, 6, 301, 5, 25195, 5, 37, 5077, 13, 11588, 5408, 7, 11, 5421, 4751, 7, 38, 24122, 13, 9405, 7, 16, 2224, 209, 1915, 3728, 20110, 7, 5, 3559, 13, 9071, 27631, 7, 6, 2307, 17867, 6, 3, 3436, 18, 3940, 5, 4663, 30345, 3892, 10, 852, 3209, 34, 12, 3, 9, 1782]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then finally pass everthing to the trainer"
      ],
      "metadata": {
        "id": "I3t6b2TkcJwy"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l82ReicTiTgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTTrainer\n",
        "\n",
        "max_seq_length = 512\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset_train,\n",
        "    peft_config=peft_config,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_arguments,\n",
        ")"
      ],
      "metadata": {
        "id": "TNeOBgZeTl2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will also pre-process the model by upcasting the layer norms in float 32 for more stable training"
      ],
      "metadata": {
        "id": "GWplqqDjb3sS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, module in trainer.model.named_modules():\n",
        "    if \"norm\" in name:\n",
        "        module = module.to(torch.float32)"
      ],
      "metadata": {
        "id": "7OyIvEx7b1GT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model"
      ],
      "metadata": {
        "id": "1JApkSrCcL3O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJFGCCoOXcgS",
        "outputId": "82d9aa22-e0b4-422f-d785-f407b3a61640"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's train the model! Simply call `trainer.train()`"
      ],
      "metadata": {
        "id": "JjvisllacNZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "_kbS7nRxcMt7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 896
        },
        "outputId": "5343b9fd-a6fc-4ad0-b485-844f3c7cdd47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhungnguyennguyen200504\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20230920_161746-ml1ehmll\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mbright-sun-17\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/hungnguyennguyen200504/huggingface\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/hungnguyennguyen200504/huggingface/runs/ml1ehmll\u001b[0m\n",
            "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [200/200 01:49, Epoch 3/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>8.062600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>6.181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>4.103700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>2.203000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.684300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.256500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.787200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.681600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.703500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.533400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.357800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.455700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>0.385300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.359400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.278500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.339900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.346100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.245100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.279400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.283000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=200, training_loss=1.4763803732395173, metrics={'train_runtime': 112.1761, 'train_samples_per_second': 28.527, 'train_steps_per_second': 1.783, 'total_flos': 264396138479616.0, 'train_loss': 1.4763803732395173, 'epoch': 3.62})"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "During training, the model should converge nicely as follows:\n",
        "\n",
        "![image](https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/images/loss-falcon-7b.png)\n",
        "\n",
        "The `SFTTrainer` also takes care of properly saving only the adapters during training instead of saving the entire model."
      ],
      "metadata": {
        "id": "H5c0ppfasK29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub"
      ],
      "metadata": {
        "id": "cbAukwMF5lIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Login to huggingface\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "SrKs-7UL5r6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Push model to hub\n",
        "trainer.push_to_hub(\"falcon-7b-sharded\")"
      ],
      "metadata": {
        "id": "dwSsElLr5_kP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W4PytmYo3Vx8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}